\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{datasolut2}
\citation{datasolut2}
\citation{datasolut2}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Deep Learning}{9}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Was ist Deep Learning?}{9}{section.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces \IeC {\"U}bersicht K\IeC {\"u}nstliche Intelligenz\relax }}{9}{figure.caption.10}\protected@file@percent }
\newlabel{overview-ki}{{3.1}{9}{Übersicht Künstliche Intelligenz\relax }{figure.caption.10}{}}
\citation{datasolut2}
\citation{datasolut2}
\citation{datasolut2}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Darstellung eines beispielhaften k\IeC {\"u}nstlichen neuronalen Netzes   (vereinfacht)\relax }}{10}{figure.caption.11}\protected@file@percent }
\newlabel{simple-net}{{3.2}{10}{Darstellung eines beispielhaften künstlichen neuronalen Netzes \\ (vereinfacht)\relax }{figure.caption.11}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Warum Deep Learning?}{10}{section.3.2}\protected@file@percent }
\citation{datasolut3}
\citation{datasolut3}
\citation{der-onliner_blogspot}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Darstellung der Performance von Deep Learning Algorithmen im Vergleich zu \IeC {\"a}lteren Lernalgorithmen\relax }}{11}{figure.caption.12}\protected@file@percent }
\newlabel{deep-learning-performance}{{3.3}{11}{Darstellung der Performance von Deep Learning Algorithmen im Vergleich zu älteren Lernalgorithmen\relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Lernverfahren}{11}{section.3.3}\protected@file@percent }
\citation{datasolut}
\citation{datasolut}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Darstellung der verschiedenen Lernverfahren\relax }}{12}{figure.caption.13}\protected@file@percent }
\newlabel{overview-machine-learning-algorithms}{{3.4}{12}{Darstellung der verschiedenen Lernverfahren\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Datensatz}{12}{section.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Trainingsdatensatz}{12}{subsection.3.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Validierungsdatensatz}{12}{subsection.3.4.2}\protected@file@percent }
\citation{datasolut}
\citation{jaai}
\citation{jaai}
\citation{jaai}
\citation{jaai}
\citation{jaai}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Testdatensatz}{13}{subsection.3.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Funktionsweise und Aufbau k\IeC {\"u}nstlicher neuronaler Netze}{13}{section.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Eingabeschicht (input layer)}{13}{subsection.3.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.2}Zwischenschichten (hidden layer)}{13}{subsection.3.5.2}\protected@file@percent }
\citation{jaai}
\citation{divis}
\citation{wiki}
\citation{jaai}
\citation{jaai}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.3}Ausgabeschicht (output layer)}{14}{subsection.3.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.4}Modellparameter}{14}{subsection.3.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.5}Hyperparameter}{14}{subsection.3.5.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.6}Gewichte und Verzerrung (Bias)}{14}{subsection.3.5.6}\protected@file@percent }
\citation{ai-united}
\citation{ai-united}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.7}Aktivierungsfunktion (activation function)}{15}{subsection.3.5.7}\protected@file@percent }
\acronymused{relu}
\acronymused{elu}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.8}Verlustfunktion (loss function)}{15}{subsection.3.5.8}\protected@file@percent }
\citation{rocketloop}
\citation{lucas_plagwitz}
\citation{lucas_plagwitz}
\citation{lucas_plagwitz}
\citation{lucas_plagwitz}
\acronymused{mse}
\acronymused{mae}
\acronymused{mbe}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.9}Fehlerr\IeC {\"u}ckf\IeC {\"u}hrung (Backpropagation)}{16}{subsection.3.5.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.9.1}Optimierungsstrategien (Optimizer)}{16}{subsubsection.3.5.9.1}\protected@file@percent }
\citation{lucas_plagwitz}
\citation{lucas_plagwitz}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.9.2}Faltungsschicht}{17}{subsubsection.3.5.9.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.9.3}Dropout}{17}{subsubsection.3.5.9.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.9.4}Normalisierung}{17}{subsubsection.3.5.9.4}\protected@file@percent }
\citation{oliver-gableske}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.9.5}Regularisierung}{18}{subsubsection.3.5.9.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Multilayer-Perzeptron (MLP)}{18}{section.3.6}\protected@file@percent }
\AC@undonewlabel{acro:mlp}
\newlabel{acro:mlp}{{3.6}{18}{Multilayer-Perzeptron (MLP)}{section*.14}{}}
\acronymused{mlp}
\acronymused{mlp}
\citation{datasolut4}
\citation{datasolut4}
\newlabel{linear-classification}{{3.5i}{19}{Lineare \hspace {-0.16cm} Klassifikation \\ mittels eines Perzeptrons\relax }{figure.caption.15}{}}
\newlabel{sub@linear-classification}{{i}{19}{Lineare \hspace {-0.16cm} Klassifikation \\ mittels eines Perzeptrons\relax }{figure.caption.15}{}}
\newlabel{non-linear-classification}{{3.5ii}{19}{Nichtlineare Klassifikation mittels MLP\relax }{figure.caption.15}{}}
\newlabel{sub@non-linear-classification}{{ii}{19}{Nichtlineare Klassifikation mittels MLP\relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Lineare Klassifikation versus Nichtlineare Klassifikation\relax }}{19}{figure.caption.15}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.7}Convolutional Neural Networks (CNNs)}{19}{section.3.7}\protected@file@percent }
\AC@undonewlabel{acro:cnns}
\newlabel{acro:cnns}{{3.7}{19}{Convolutional Neural Networks (CNNs)}{section*.16}{}}
\acronymused{cnns}
\acronymused{2d}
\acronymused{3d}
\acronymused{cnns}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Darstellung eines beispielhaften \acs {cnn}\relax }}{19}{figure.caption.17}\protected@file@percent }
\acronymused{cnn}
\acronymused{cnns}
\acronymused{2d}
\acronymused{3d}
\@setckpt{kapitel3/DeepLearning}{
\setcounter{page}{20}
\setcounter{equation}{0}
\setcounter{enumi}{4}
\setcounter{enumii}{2}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{3}
\setcounter{section}{7}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{6}
\setcounter{table}{0}
\setcounter{@todonotes@numberoftodonotes}{0}
\setcounter{parentequation}{0}
\setcounter{lstnumber}{15}
\setcounter{Item}{9}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{0}
\setcounter{float@type}{8}
\setcounter{caption@flags}{0}
\setcounter{ContinuedFloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{@index}{1}
\setcounter{@plane}{0}
\setcounter{@row}{0}
\setcounter{@col}{0}
\setcounter{use@args}{0}
\setcounter{@record}{0}
\setcounter{arg@index}{0}
\setcounter{break@count}{0}
\setcounter{index@count}{0}
\setcounter{loop@count}{0}
\setcounter{VerbboxLineNo}{0}
\setcounter{lstlisting}{0}
\setcounter{section@level}{1}
}
