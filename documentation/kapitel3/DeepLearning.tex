\chapter{Deep Learning}

\section{Was ist Deep Learning?}

Unter Deep Learning (zu deutsch tiefes Lernen) versteht man ein Teilgebiet des maschinellen Lernens (\acs{s.} \acs{abb.} \ref{overview-ki}), welches sich mit künstlichen neuronalen Netzen und große Datenmengen befasst. Es eignet sich für eine Vielzahl von Anwendungsfällen wie beispielsweise für selbstfahrende Autos, in der Medizin als auch im Marketing. \cite{datasolut2}\\

Mit Deep Learning können Probleme gelöst werden, die ohne diese Ansätze nicht lösbar wären. Tiefes Lernen ist allerdings sehr rechenaufwändig, wodurch das Training über Monate hinweg andauern kann, um gute Entscheidungen treffen zu können. Gründe hierfür sind komplexe Architekturen sowie eine Vielzahl an Modell-Parametern. \cite{datasolut2} \\

\begin{figure}[H]
	\centering
	\includegraphics[width=\textwidth]{kapitel3/images/KI_Uebersicht.png}
	\caption{Übersicht Künstliche Intelligenz}
	\label{overview-ki}
	\vspace{0.2cm}
	\quelle\url{https://datasolut.com/wp-content/uploads/2019/11/KI-und-Deep-Learning.002-e1558385989498.jpeg}
\end{figure}

Die Grundlage des Deep Learnings stellt die Verwendung von künstlichen neuronalen Netzen dar. Unter künstlichen neuronalen Netzen versteht man Algorithmen, die nach dem biologischen Vorbild des menschlichen Gehirns modelliert sind. Diese werden eingesetzt, um beispielsweise Muster in Bildern zu erkennen oder Bilder zu klassifizieren. \cite{datasolut2}\\

\newpage

Ein einfaches künstliches neuronales Netz besteht dabei aus einer Eingabeschicht (Input Layer), einer Zwischenschicht (Hidden Layer) und einer Ausgabeschicht (Output Layer) \cite{datasolut2}. Abbildung \ref{simple-net} zeigt eine einfache Darstellung eines beispielhaften künstlichen neuronalen Netzes.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.65\textwidth]{kapitel3/images/Simples_Neuronales_Netz.jpg}
	\caption{Darstellung eines beispielhaften künstlichen neuronalen Netzes \\ (vereinfacht)}
	\label{simple-net}
	\vspace{0.2cm}
	\quelle\url{https://datasolut.com/wp-content/uploads/2019/10/ku%CC%88nstliche-neuronale-Netze.jpg}
\end{figure}

Von tiefem Lernen spricht man dann, wenn die eingesetzten neuronalen Netze mehr als eine Zwischenschicht haben.  \cite{datasolut2} 

\section{Warum Deep Learning?}

Es gibt Problemstellungen (wie beispielsweise die unstrukturierte Bilderkennung), die sich besonders gut mit künstlichen neuronalen Netzen lösen lassen. Das Erlernen dieser komplexen Muster ist jedoch mit klassischen Machine Learning Algorithmen nur sehr schwer lösbar. Hier kommen dann tiefe künstliche neuronale Netze zum Einsatz. Je größer die Datenmenge ist, die zum Lernen verwendet wird, desto besser funktioniert das tiefe Lernen \cite{datasolut2}. In \acs{abb.} \ref{deep-learning-performance} ist die Performance von Deep Learning Algorithmen im Vergleich zu älteren Lernalgorithmen dargestellt.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.4]{kapitel3/images/Deep_Learning_Performance.png}
	\caption{Darstellung der Performance von Deep Learning Algorithmen im Vergleich zu älteren Lernalgorithmen}
	\label{deep-learning-performance}
	\vspace{0.2cm}
	\quelle\url{https://datasolut.com/wp-content/uploads/2019/11/Warum-deep-learning-1024x742.png}
\end{figure}

\section{Lernverfahren}

Beim maschinellen Lernen bzw. beim Deep Learning stehen drei unterschiedliche Lernverfahren zur Verfügung:

\begin{itemize}
	
	\item Überwachtes Lernen (Supervised Learning)\\
	Das überwachte Lernen nutzt für den Lernprozess bekannte Daten, um daraus Muster und Zusammenhänge zu erkennen. Die Muster werden  anhand eines Trainingsdatensatzes (Beispieldaten) erlernt. Dabei wird der Zusammenhang zu einer Zielvariable erlernt und es wird versucht diese richtig vorherzusagen. \cite{datasolut3}
	
	\item Unüberwachtes Lernen (Unsupervised Learning)\\
	Das unüberwachte Lernen nutzt für den Lernprozess keine Beispieldaten, sondern Rohdaten, aus denen eigenständig Muster erkannt werden sollen. \\
	Der hauptsächliche Unterschied zum überwachten Lernen ist also, dass das unüberwachte Lernen nicht dafür ausgelegt ist, eine Vorhersage für eine bekannte Zielvariable zu treffen. \cite{datasolut3}
	\item Bestärkendes Lernen (Reinforcment Learning)\\
	Anders als das überwachte \acs{bzw} unüberwachte Lernen nutzt das bestärkende Lernen zunächst keine Daten, sondern diese entstehen in einer Simulationsumgebung nach einem Versuch-und-Irrtum-Verfahren. \cite{der-onliner_blogspot}
\end{itemize}

In Abbildung \ref{overview-machine-learning-algorithms} ist eine Übersicht über die  verschiedenen Lernverfahren dargestellt.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.6\textwidth]{kapitel3/images/lernverfahren.png}
	\caption{Darstellung der verschiedenen Lernverfahren}
	\label{overview-machine-learning-algorithms}
	\vspace{0.2cm}
	\quelle\url{https://1.bp.blogspot.com/-xstYqLb9OBw/XSYZUUD0WrI/AAAAAAAAML4/4sxvpGjIsDgmR7bDYyhcKdfM0TbvIIHdwCEwYBhgL/s400/machine-learning-lernverfahren.png}
\end{figure}

Welches Lernverfahren schlussendlich eingesetzt wird, hängt hierbei vom Anwendungsfall ab sowie mit den daraus resultierenden Datensätzen. 

\section{Datensatz}

Damit ein künstliches neuronales Netz mit überwachtem Lernen, seine Aufgabe erfüllen kann, muss zunächst ein Datensatz erstellt werden, damit das Netz trainiert werden kann. Der Datensatz besteht dabei aus einem Trainingsdatensatz, einem Validierungsdatensatz sowie aus einem Testdatensatz. \\

\subsection{Trainingsdatensatz}

Der Trainingsdatensatz ist ein Beispieldatensatz der für das Lernen der Muster und Zusammenhänge in den Daten verwendet wird. Das Modell des neuronalen Netz nutzt also diese Daten um zu lernen. \cite{datasolut} \\

\subsection{Validierungsdatensatz}

Der Validierungsdatensatz ist ebenso ein Beispieldatensatz, welcher für die Abstimmung der Hyperparameter des Modells des neuronalen Netzes verwendet wird. Dadurch wird das sogenannte \glqq Overfitting\grqq{} (Überanpassung) des Modells auf die Trainingsdaten verhindert. \cite{datasolut} \\

\subsection{Testdatensatz}

Der Testdatensatz ist ebenfalls ein Beispieldatensatz, jedoch sind die Daten von den Trainingsdaten unabhängig. Die Testdaten werden beim Training des neuronalen Netzes nicht benutzt, sondern dienen zur abschließenden Verifikation des Modells. Dadurch kann die Qualität des Modell erfasst werden, damit man eine Aussage über die Leistungsfähigkeit des neuronalen Netzes treffen kann. \cite{datasolut} \\

\section{Funktionsweise und Aufbau künstlicher neuronaler Netze}

Die Neuronen (Knotenpunkte) eines künstlichen neuronalen Netzes sind schichtweise angeordnet. Diese werden normalerweise in einer festen Hierarchie miteinander verbunden. Die Neuronen sind dabei im Regelfall zwischen zwei Schichten verbunden, jedoch in Ausnahmefällen aber auch innerhalb einer Schicht. \cite{jaai} \\

Die Informationen fließen beginnend mit der Eingabeschicht über eine oder mehrere Zwischenschichten bis hin zur Ausgabeschicht. Dabei ist der Ausgabewert eines Neurons der Eingabewert des nächsten Neurons. \cite{jaai} \\

Künstliche neuronale Netze werden meist schematisch horizontal dargestellt (wie z.B. in Abbildung \ref{fig:simples-neuronales-netz}). Die Eingabeschicht befindet sich dabei auf der linken Seite  gefolgt von den Zwischenschichten in der Mitte und der Ausgabeschicht auf der rechten Seite.
Die Anzahl der Schichten die in einem künstlichen neuronalen Netz verwendet werden, ist eine wichtige beschreibende Information. Enthält ein Netz zum Beispiel drei Schichten, so spricht man von einem drei-schichtigen neuronalen Netz. \cite{jaai}

\subsection{Eingabeschicht (input layer)}
	
	Die Eingabeschicht definiert den Startpunkt des Informationsflusses in einem künstlichen neuronalen Netz. Die Eingangssignale werden dabei von den Neuronen am Anfang dieser Schicht entgegengenommen und am Ende gewichtet an die Neuronen der ersten Zwischenschicht weitergegeben. \cite{jaai}
	
\subsection{Zwischenschichten (hidden layer)}

	Zwischen der Eingabe- und der Ausgabeschicht befindet sich mindestens eine Zwischenschicht. Je mehr Zwischenschichten ein künstliches neuronales Netz besitzt, desto tiefer ist das Netz, jedoch bewirkt jede weitere hinzukommende Zwischenschicht auch einen Anstieg der benötigten Rechenleistung. \cite{jaai}
	
\subsection{Ausgabeschicht (output layer)}

	Die Ausgabeschicht bildet die letzte Schicht eines künstlichen neuronalen Netzes, wobei diese sich hinter den Zwischenschichten befindet. Sie stellt das Ende des Informationsflusses eines künstlichen neuronalen Netz dar und enthält das Ergebnis der Informationsverarbeitung. \cite{jaai}
	
\subsection{Modellparameter}

Die Modellparameter eines künstlichen neuronalen Netzes werden beim Training des Netzes selbständig erlernt. Basierend auf bereits vorhandenen Parametern trainiert der Trainingsalgorithmus und versucht dadurch, die Modellparameter immer weiter zu verbessern. \cite{divis}

\subsection{Hyperparameter}

Die Hyperparameter eines künstlichen neuronalen Netz dienen zur Steuerung des Trainingsalgorithmus. In der Regel müssen die Werte der Hyperparameter im Gegensatz zu den Modellparametern vor dem eigentlichen Training des Modells festgelegt werden, wodurch diese nicht selbständig erlernt werden können. \cite{wiki} \\

Einige Beispiele für Hyperparameter sind:

\begin{enumerate}
	\item Lerngeschwindigkeit (learning rate):\\
	Schrittgrößte in Richtung Minimum der Fehlerfunktion pro Iteration 
	\item Batch Size:\\
	Anzahl an Beispielen welche pro Iteration in das Netz eingespeißt werden
	\item Anzahl Epochen:\\
	Anzahl der Trainingsdurchläufe über den Datensatz
\end{enumerate}
	
\subsection{Gewichte und Verzerrung (Bias)}

	Durch die Gewichte wird die Intensität des Informationsflusses entlang einer Verbindung eines künstlichen neuronalen Netzes beschrieben. Dazu vergibt jedes Neuron ein Gewicht für die durchfließende Information. Diese wird anschließend mit diesem Gewicht gewichtet und es wird ein Wert für die neuronen-spezifische Verzerrung (Bias) addiert. Das resultierende Ergebnis wird in der Regel durch eine sogenannte Aktivierungsfunktion geleitet, bevor es an die Neuronen der nächsten Schicht weitergegeben wird. \cite{jaai} \\
	
	Während des Trainingsprozesses werden die Gewichte und Verzerrungen so angepasst, dass das Endresultat möglichst genau den Anforderungen entspricht. \cite{jaai}
	
\subsection{Aktivierungsfunktion (activation function)}

	Aktivierungsfunktionen spielen in künstlichen neuronalen Netzen eine bedeutende Rolle, da sie dabei helfen, die komplizierte und nichtlineare funktionale Beziehung zwischen den Eingangsdaten und den abhängigen Ergebnissen zu lernen und zu verstehen. Ein Eingangssignal eines Neurons wird dabei in ein Ausgangssignal konvertiert, welches anschließend als Eingabe der nächsten Schicht verwendet wird. \cite{ai-united} \\
	
	Einige Beispiele für Aktivierungsfunktionen sind:
	
	\begin{center}
	\begin{tabular}[t]{|M{2.5cm}|M{6cm}|M{5cm}|}
		\hline
		\textbf{Bezeichnung} & \textbf{Funktion} & \textbf{Plot} \\
		\hline
		\begin{tabular}{l} Identität \end{tabular} &  
		\begin{tabular}{l} $ f(x) = x $ \end{tabular} &
		\begin{tabular}{l}
			\addvbuffer[0.05cm]{\includegraphics[scale=0.5]{kapitel3/images/idendity.png}}
		\end{tabular} \\
		\hline
		\begin{tabular}{l} Sigmoid \end{tabular} &  
		\begin{tabular}{l} $ f(x) = \frac{1}{1 + e^{-x}} $ \end{tabular} &
		\begin{tabular}{l}
			\addvbuffer[0.05cm]{\includegraphics[scale=0.5]{kapitel3/images/sigmoid.png}}
		\end{tabular} \\
		\hline
		\begin{tabular}{l} \acs{relu} \end{tabular} &  
		\begin{tabular}{l} $ f(x) = \max (0,x) $ \end{tabular} &
		\begin{tabular}{l}
			\addvbuffer[0.05cm]{\includegraphics[scale=0.5]{kapitel3/images/relu.png}}
		\end{tabular} \\
		\hline
		\begin{tabular}{l} \acs{elu} \end{tabular} &  
		\begin{tabular}{l} $ f(\alpha, x) = \begin{cases} \alpha (e^x - 1) \quad \textrm{für} \ x \leq 0 \\ x \hspace{1.75cm} \textrm{für} \ x > 0 \end{cases} $ \end{tabular} &
		\begin{tabular}{l}
			\addvbuffer[0.05cm]{\includegraphics[scale=0.25]{kapitel3/images/elu.jpg}}
		\end{tabular} \\
		\hline
	\end{tabular}
	\end{center}

\subsection{Verlustfunktion (loss function)}

	Die Verlustfunktion wird zur Berechnung des Fehlers zwischen den realen Ergebnissen und erhaltenen Antworten des künstlichen neuronalen Netzes verwendet. Das Ziel des Lernprozesses ist die Minimierung dieser Fehler.  \cite{ai-united} \\

	Einige Beispiele für Verlustfunktionen sind:
	
	\begin{center}
	\begin{tabular}[t]{|l|l|}
		\hline
		\textbf{Bezeichnung} & \textbf{Funktion} \\
		\hline
		Mittlere quadratische Abweichung  &  
		\addvbuffer[0.05cm]{
			$ \textrm{\acs{mse}} = \frac{\sum_{i=1}^{n} (y_i - \hat{y_i})^2}{n} $
		} \\
		\hline
		Mittlerer absoluter Fehler  &  
		\addvbuffer[0.05cm]{
			$ \textrm{\acs{mae}} = \frac{\sum_{i=1}^{n} |y_i - \hat{y_i}|}{n} $
		} \\
		\hline
		Mittlerer Bias Fehler  &  
		\addvbuffer[0.05cm]{
			$ \textrm{\acs{mbe}} = \frac{\sum_{i=1}^{n} (y_i - \hat{y_i})}{n} $
		} \\
		\hline
		
	\end{tabular}
	\end{center}

\subsection{Fehlerrückführung (Backpropagation)}

	Bei der Fehlerrückführung (Backpropagation) wird die Antwort des künstlichen neuronalen Netzes mit dem gewünschten Ergebnis verglichen. Dabei wird der Fehler bestimmt und dieser wird anschließend rückwärtig in das Netz gespeist, wodurch die Gewichte der Neuronen so angepasst werden, dass der Fehler immer kleiner wird. In der Praxis werden dafür verschiedene Optimierungsstrategien eingesetzt. \cite{rocketloop}
	
\subsubsection{Optimierungsstrategien (Optimizer)}

	\begin{enumerate}
		\item \textbf{Gradientenverfahren:}
		
			Das Gradientenverfahren beschreibt einen Algorithmus, der für eine Verlustfunktion, den Eingabeparameter in entgegengesetzter Richtung des Gradienten aktualisiert. Über die  Lerngeschwindigkeit (learn rate) kann festgelegt werden, wie weit der Algorithmus sich in jeder Iteration vom Ausgangspunkt entfernen darf. \cite{lucas_plagwitz}
		
		\item \textbf{Momentum Optimierer:}
		
			Der Momentum Optimierer ist ein erweiterter Ansatz des Gradientenverfahrens. Während das \glqq Standardgradientenverfahren\grqq{} in jedem Iterationsschritt immer in entgegengesetzte Richtung des lokalen Gradienten absteigt, nimmt der Momentum Optimierer Rücksicht auf die Gradienten der vorherigen Iterationen. \cite{lucas_plagwitz}
			
		\item \textbf{Adaptive Optimierungsstrategie:}
		
			Ein Abstiegt wie ihn die Gradientenverfahren erledigen, kann unter Umständen nicht dir richtige Wahl zur Lösung des Problems darstellen. Daher wurden adaptive Algorithmen entwickelt, die eine Alternative zu den Gradientenverfahren darstellen. Dabei wird folgende Idee verfolgt: Man passt die Lernrate dynamisch an die Parameter an und führt größere Aktualisierungen für seltene Parameter durch und kleinere Aktualisierungen für häufige Parameter. \cite{lucas_plagwitz}
			
			\begin{enumerate}
				\item \textbf{AdaGrad:}
				
					Der Kerngedanke hinter AdaGrad ist das Herunterskalieren des Gradientenvektors, \acs{d.h.} die Lernrate wird pro Dimension nach und nach verringert, wobei die Verringerung bei steilen Dimensionen schneller erfolgt. \cite{lucas_plagwitz}
					
				\item \textbf{RMSProp:}
				
					RMSProp ist eine leicht modifizierte Version des AdaGrad Optimierers. Dabei werden die Gradienten der letzten Iterationen unter exponentiellem Zerfall  berücksichtigt. Im Allgemeinen lässt sich sagen, dass RMSProp schneller konvergiert als AdaGrad. \cite{lucas_plagwitz}
				
					
			\end{enumerate}
		
			
		\item \textbf{Adam Optimierung:}
		
			Die Adam Optimierung ist eine Kombination aus der Idee des Momentum Optimierers und RMSProp. Das Verfahren betrachtet hierbei sowohl den Durchschnitt der vorigen Gradienten als auch den Durchschnitt der quadrierten Gradienten, beide unter exponentiellem Zerfall. \cite{lucas_plagwitz}
			
	\end{enumerate}

\subsubsection{Faltungsschicht}

Arbeitet man mit Daten mit großter Dimensionalität, wie zum Beispiel Bildern, wird das Training mit vollständig verbundenen Netzen schnell unpraktikabel. Allein die Kombination eines ein-megapixel großen Bildes mit einer Schicht aus tausend Neuronen würde eine Milliarde Modellparameter ergeben.
Es bietet sich daher das Arbeiten mit der Faltung an, wobei nur ein Faltungskern erlernt werden muss.

\subsubsection{Dropout}

Eine weit verbreitete Methode um das Überstimmen von neuronalen Netzen zu minimieren sind Dropout-Schichten. Die Idee ist, dass ein für das Netz wichtiges Merkmal nicht aus der Aktivierung eines einzelnen Neurons besteht, sondern aus der Kombination mehrerer.
Um die Abhänigkeit des Outputs des Netzes von einzelnen Aktivierungen zu verhindern, werden diese mit einer festgelegten Wahrscheinlichkeit auf null gesetzt. Dies geschieht nur während des Trainings und wird zur Inferenz abgeschaltet.

\subsubsection{Normalisierung}

Die Normalisierung der Input-Daten gilt weithin als Best-Practice. Der wichtigste Grund dafür ist schnellere Konvergenz und damit ein schnellerer Lernprozess.
Dies lässt sich damit erklären, dass das Lernverfahren als eine Minimumssuche auf der Oberfläche der Fehlerfunktion verstanden werden kann, wobei die Größenordnung der Input-Daten die Verzerrung dieser Oberfläche bestimmen. Da das Netz den Wert der Fehlerfunktion mit seinen Parametern minimieren soll, müssen bei unterschiedlich großen Inputs auch die Gewichte unterschiedlich groß sein. Das wiederum zieht unterschiedlich große ideale Lernraten nach sich. Diese Verzerrung der Oberfläche der Fehlerfunktion kann durch Normalisierung der Daten minimiert werden.

\subsubsection{Regularisierung}

Neuronale Netze bilden Input über ihre Gewichte auf einen gewissen Output ab. Ist die Größenordnung mancher Gewichte größer als die von anderen, ist die Wahrscheinlichkeit hoch, dass das Netz überstimmt ist. Eine kleine Abweichung im Input kann dann drastische Auswirkungen auf den Output haben.
Um zu verhindern, dass der Lernprozess die Gewichte beliebig groß gestaltet, kann an die Fehlerfunktion ein zusätzlicher Term angefügt werden, welcher die Größe der Gewichte beinhaltet. Eine L2-Regularisierung zum Beispiel, multipliziert das Quadrat der Größe der Gewichte mit einem Vorfaktor, einem Hyperparameter, und addiert das Ergebniss auf den Wert der Fehlerfunktion. Große Gewichte werden so bestraft.


\section{Convolutional Neural Networks (CNNs)}

	\acf{cnns} können besonders effizient mit \acs{2d}- \acs{bzw} \acs{3d}-Eingabedaten arbeiten. Insbesondere werden \acs{cnns} für die Objektdetektion in Bildern angewendet \cite{datasolut4}. In \acs{abb.} \ref{example-cnn} kann man die Darstellung eines beispielhaftes \acs{cnn} sehen. \\
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.9\textwidth]{kapitel3/images/cnn.png}
		\caption{Darstellung eines beispielhaften \acs{cnn}}
		\label{example-cnn}
		\vspace{0.2cm}
		\quelle\url{https://de.wikipedia.org/wiki/Convolutional_Neural_Network#/media/Datei:Typical_cnn.png}
	\end{figure}

	Der Unterschied zu den klassischen künstlichen neuronalen Netzen liegt in der Architektur der \acs{cnns}: Die Zwischenschicht basiert hierbei auf einer Abfolge von Faltungs- und Poolingoperationen. Bei der Faltung wird ein sogenannter Faltungskernel über die Daten geschoben und das Ergebnis der Faltungsoperation wird berechnet. Anschließend werden die Neuronen aktualisiert. Die nachfolgende Poolingoperation sorgt dann dafür, dass die Ergebnisse vereinfacht werden. Dadurch bleiben nur die wichtigsten Informationen erhalten.	Des Weiteren wird dadurch erreicht, dass die \acs{2d}- oder \acs{3d}-Eingangsdaten kleiner werden. \cite{datasolut4}
	
\section{Multilayer-Perzeptron (MLP)}

Ein einzelnes Perzeptron kann für sich genommen lediglich eine lineare Klassifikation erzielen (\acs{s.} \acs{abb.} \ref{linear-classification}) Es ist jedoch des Öfteren notwendig, weitaus komplexere Klassifikationen zu bewerkstelligen. Dies lässt sich erreichen, indem mehrere Perzeptronen miteinander verschaltet werden. Dabei werden die einzelnen Perzeptrone zunächst in Schichten angeordnet. Die Perzeptronen einer Schicht, sind dann jeweils mit jedem Perzeptron der folgenden Schicht verschaltet. Innerhalb einer Schicht werden die Perzeptronen nicht miteinander verbunden und es darf auch keine zyklischen Verschaltungen zwischen den Schichten geben. Das resultierende Ergebnis wird dann als sogenanntes \acf{mlp} bezeichnet. Die erste Schicht ist hierbei die Eingabeschicht. Sie ist dafür zuständig, die einzelnen Werte der Eingänge über die Eingabeperzeptronen an jedes Perzeptron der nächsten Schicht weiter zu leiten. Nach der Eingabeschicht folgen eine \acs{bzw} mehrere Zwischenschichten. In den Zwischenschichten findet dann der eigentliche Klassifikationsprozess statt. Die nichtlineare Klassifikation (s. Abb. \ref{non-linear-classification}) entsteht dabei durch den Einsatz von mehreren Perzeptronen. Nach den Zwischenschichten folgt letztendlich die Ausgabeschicht, welche aus den sogenannten Ausgabeperzeptronen besteht. Das Ergebnis des Klassifikationsprozesses wird dann schlussendlich über diese Schicht ausgegeben. Jede Schicht des \acs{mlp} kann dabei aus mehreren Perzeptronen bestehen, aber es muss immer mindestens ein Perzeptron vorhanden sein. \cite{oliver-gableske}

\begin{figure}[h]
	\captionsetup[subfigure]{position=b}
	\centering
	\begin{subfigure}[b]{0.3\textwidth}
		\centering
		\includegraphics[width=\textwidth]{kapitel3/images/linear_classification.jpg}
		\caption{Lineare \hspace{-0.16cm} Klassifikation \\ mittels eines Perzeptrons}
		\label{linear-classification}
	\end{subfigure}
	\hspace{1em}
	\begin{subfigure}[b]{0.3\textwidth}
		\centering
		\includegraphics[width=\textwidth]{kapitel3/images/non_linear_classification.jpg}
		\caption{Nichtlineare Klassifikation mittels MLP}
		\label{non-linear-classification}
	\end{subfigure}
	\caption{Lineare Klassifikation \acs{vs.} Nichtlineare Klassifikation}
	\quelle\url{https://www.informatik.uni-ulm.de/ni/Lehre/WS04/ProSemNN/pdf/MLP.pdf}
\end{figure}





